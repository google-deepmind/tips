{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlILc7jN0MO"
      },
      "source": [
        "Copyright 2025 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qs1CcsHIxtfx"
      },
      "outputs": [],
      "source": [
        "# @title TIPS Demo notebook\n",
        "\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "\n",
        "#  https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXG9RJf8U5Ti"
      },
      "source": [
        "### Imports and functions\n",
        "\n",
        "Please follow the installation guide before you run the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJgQoq1XgEP3"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import mediapy as media\n",
        "import tensorflow_text\n",
        "\n",
        "from tips.scenic.configs import tips_model_config\n",
        "from tips.scenic.models import text\n",
        "from tips.scenic.models import tips\n",
        "from tips.scenic.utils import checkpoint\n",
        "from tips.scenic.utils import feature_viz\n",
        "\n",
        "def load_and_preprocess_image(image_path, image_shape):\n",
        "  with open(image_path, 'rb') as f:\n",
        "    image = np.array(Image.open(f)).astype(np.float32) / 255.\n",
        "  image = jax.image.resize(image, (*image_shape, 3), method='bilinear')\n",
        "  return image.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBtTQrRNfbi"
      },
      "source": [
        "### Configure the TIPS model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eMXX0d3Idr7"
      },
      "outputs": [],
      "source": [
        "# Set the input image shape.\n",
        "image_width = 448  # @param {type: \"number\"}\n",
        "image_shape = (image_width,) * 2\n",
        "\n",
        "variant = 'tips_oss_b14_highres_distilled'  # @param ['tips_oss_g14_highres', 'tips_oss_g14_lowres', 'tips_oss_so400m14_highres_largetext_distilled', 'tips_oss_l14_highres_distilled', 'tips_oss_b14_highres_distilled', 'tips_oss_s14_highres_distilled']\n",
        "\n",
        "# Model and checkpoint configuration.\n",
        "model_config = tips_model_config.get_config(variant)\n",
        "\n",
        "# Add the checkpoints in this directory.\n",
        "checkpoint_dir = '../checkpoints/'  # @param {type: \"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cuJRuZ2U8qZ"
      },
      "source": [
        "### Load the vision and text encoders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK2JLKaR36jt"
      },
      "outputs": [],
      "source": [
        "# Load the vision encoder.\n",
        "model_vision = tips.VisionEncoder(\n",
        "    variant=model_config.variant,\n",
        "    pooling=model_config.pooling,\n",
        "    num_cls_tokens=model_config.num_cls_tokens,\n",
        ")\n",
        "\n",
        "init_params_vision = model_vision.init(\n",
        "    jax.random.PRNGKey(0), jnp.ones([1, *image_shape, 3]), train=False)\n",
        "\n",
        "print(f'Loading the vision encoder weights for variant {variant}.')\n",
        "params_vision = checkpoint.load_checkpoint(\n",
        "    os.path.join(checkpoint_dir, f'{variant}_vision.npz'),\n",
        "    init_params_vision['params'])\n",
        "print('Done.')\n",
        "\n",
        "# Load the text encoder.\n",
        "model_text = tips.TextEncoder(\n",
        "    variant=model_config.variant)\n",
        "init_params_text = model_text.init(\n",
        "    jax.random.PRNGKey(0),\n",
        "    ids=jnp.ones((2, 64), dtype=jnp.int32),\n",
        "    paddings=jnp.zeros((2, 64), dtype=jnp.int32),\n",
        "    train=False)\n",
        "init_params_text['params']['temperature_contrastive'] = np.array(0, dtype=np.float32)\n",
        "print(f'Loading the text encoder weights for variant {variant}')\n",
        "params_text = checkpoint.load_checkpoint(\n",
        "    os.path.join(checkpoint_dir, f'{variant}_text.npz'),\n",
        "    init_params_text['params'])\n",
        "print('Done.')\n",
        "\n",
        "# Load the tokenizer.\n",
        "tokenizer_path = os.path.join(checkpoint_dir, 'tokenizer.model')\n",
        "tokenizer = text.Tokenizer(tokenizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mryeP_HySVZ"
      },
      "source": [
        "### Run inference and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bapmyzSnBu8v"
      },
      "outputs": [],
      "source": [
        "# Add your images in this directory.\n",
        "image_dir = '../images/'  # @param {type: \"string\"}\n",
        "image_paths = glob.glob(os.path.join(image_dir, '*'))\n",
        "\n",
        "# The text inputs to be contrasted.\n",
        "text_inputs = [\n",
        "    'A ship',\n",
        "    'holidays',\n",
        "    'a toy dinosaur',\n",
        "    'Two astronauts',\n",
        "    'A streetview image of a fastfood restaurant',\n",
        "    'a cat',\n",
        "    'a dog',\n",
        "    'two cows',\n",
        "]\n",
        "\n",
        "for image_path in image_paths:\n",
        "  # Load the image.\n",
        "  image = load_and_preprocess_image(image_path, image_shape)\n",
        "\n",
        "  # Run inference on the image.\n",
        "  spatial_features, embeddings_vision = model_vision.apply(\n",
        "      {'params': params_vision}, image[None], train=False)\n",
        "  cls_token = feature_viz.normalize(embeddings_vision[:, 0, :])  # Choose the first CLS token.\n",
        "\n",
        "  # Run inference on text.\n",
        "  text_ids, text_paddings = tokenizer.tokenize(text_inputs, max_len=64)\n",
        "  embeddings_text = model_text.apply(\n",
        "      {'params': params_text},\n",
        "      ids=text_ids,\n",
        "      paddings=text_paddings,\n",
        "      train=False)\n",
        "  embeddings_text = feature_viz.normalize(embeddings_text)\n",
        "\n",
        "  # Compute cosine similariy.\n",
        "  cos_sim = nn.softmax(\n",
        "      ((cls_token @ embeddings_text.T) /\n",
        "       params_text['temperature_contrastive']), axis=-1)\n",
        "  label_idxs = jnp.argmax(cos_sim, axis=-1)\n",
        "  cos_sim_max = jnp.max(cos_sim, axis=-1)\n",
        "  label_predicted = text_inputs[label_idxs[0].item()]\n",
        "  similarity = cos_sim_max[0].item()\n",
        "\n",
        "  # Visualize the results.\n",
        "  pca_obj = feature_viz.PCAVisualizer(spatial_features)\n",
        "  image_pca = pca_obj(spatial_features)[0]\n",
        "  media.show_images(\n",
        "      [image, image_pca], width=image_width,\n",
        "      titles=['Input image', f'{label_predicted},  prob: {similarity*100:.1f}%']\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XXG9RJf8U5Ti",
        "5cuJRuZ2U8qZ"
      ],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "TIPS Demo",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "18Aq6CW6qPm4daIQO37NHN46EYk6cx1j2",
          "timestamp": 1676239803755
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
